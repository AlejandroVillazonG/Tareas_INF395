{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlejandroVillazonG/Tareas_INF395/blob/main/T2/2_subclases_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7m720kEWTx_"
      },
      "source": [
        "<center><img src=\"https://www.inf.utfsm.cl/images/slides/Departamento-de-Informtica_HORIZONTAL.png\" title=\"Title text\" width= 800 /></center>\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "<H1 align='center'> DESAFÍO TAREA 2</H1>\n",
        "\n",
        "<H3 align='center'> INF395 2023-2 </H3>\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "## Integrantes:\n",
        "* Joaquín Aguirre (201910031-9)\n",
        "* Alejandro Villazón (201910009-2)\n",
        "* Dominique Yessouroun (201910005-K)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvdBh0hkWTyO"
      },
      "source": [
        "Importamos las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WSGUBsGfWTyP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "import json\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "import warnings\n",
        "# Ignorar las advertencias\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos funciones auxiliares:"
      ],
      "metadata": {
        "id": "VmhHidYnW8bI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(main_path, path_image, image_size):\n",
        "    image = keras.utils.load_img(main_path + path_image)\n",
        "    image = image.resize((image_size, image_size))\n",
        "    return keras.utils.img_to_array(image, dtype='uint8')\n",
        "\n",
        "def preprocess_train_test_set(main_path, paths, image_size):\n",
        "    return np.array([preprocess_image(main_path, path_image, image_size) for path_image in paths])"
      ],
      "metadata": {
        "id": "QTZzndTLW_Ju"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_macro_f1(y_true, y_pred, num_classes):\n",
        "    \"\"\"\n",
        "    Calcula el Macro F1-Score.\n",
        "    \"\"\"\n",
        "    y_pred = tf.one_hot(tf.argmax(y_pred, axis=1), depth=num_classes)\n",
        "\n",
        "    tp = tf.cast(tf.math.count_nonzero(y_pred * y_true, axis=1), tf.float32)\n",
        "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1-y_true), axis=1), tf.float32)\n",
        "    fn = tf.cast(tf.math.count_nonzero((1-y_pred) * y_true, axis=1), tf.float32)\n",
        "\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "\n",
        "    f1 = 2*precision*recall / (precision + recall)\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "\n",
        "    return tf.reduce_mean(f1)\n",
        "\n",
        "def transform_dishes(original_dishes, mapping_dishes, category_mapping):\n",
        "    transformed_dishes = {}\n",
        "    for original_key, dish in original_dishes.items():\n",
        "        for category_key, category_value in category_mapping.items():\n",
        "            if dish in mapping_dishes[category_value].values():\n",
        "                # Encontrar la clave interna dentro del diccionario de categoría\n",
        "                internal_key = [int(k) for k, v in mapping_dishes[category_value].items() if v == dish][0]\n",
        "                # Convertir la clave original a int para guardarla en el resultado\n",
        "                original_key_int = int(original_key)\n",
        "                # Asegurar que la categoría exista en el diccionario resultante\n",
        "                if category_key not in transformed_dishes:\n",
        "                    transformed_dishes[category_key] = {}\n",
        "                # Agregar el mapeo al diccionario resultante\n",
        "                transformed_dishes[category_key][original_key_int] = internal_key\n",
        "    return transformed_dishes\n",
        "\n",
        "def create_model(image_size, num_classes):\n",
        "  cnn_model = ResNet50(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "  for layer in cnn_model.layers:\n",
        "      layer.trainable = False\n",
        "  model = keras.Sequential([\n",
        "      cnn_model,\n",
        "      layers.GlobalAveragePooling2D(), #\n",
        "      layers.Reshape((1, -1)), #\n",
        "      layers.LSTM(256), #\n",
        "      # layers.Conv2D(512, 2, activation='relu'),\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      layers.Dropout(0.5),\n",
        "      layers.Dense(num_classes, activation='softmax')\n",
        "  ])\n",
        "  def macro_f1(y_true, y_pred):\n",
        "    return create_macro_f1(y_true, y_pred, num_classes)\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.AdamW(),\n",
        "                loss=['categorical_crossentropy'],\n",
        "                metrics=[macro_f1])\n",
        "  return model"
      ],
      "metadata": {
        "id": "YNdBJwNSXCTP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "E_S = keras.callbacks.EarlyStopping(monitor='val_macro_f1', mode='max',\n",
        "                                    patience=10, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "5LAyfQYRhxNX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos conectamos al drive:"
      ],
      "metadata": {
        "id": "9oYVGuIYXjFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M2A0Nv4WlFv",
        "outputId": "981b628e-a4cc-44dc-d1ce-113009bb3ba5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dHG0rtlsWTyW"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/INF395/T2/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesar imágenes"
      ],
      "metadata": {
        "id": "bbKmwOCq_JpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '{path}inf-395-tarea-2.zip'  > /dev/null"
      ],
      "metadata": {
        "id": "zt_ZZPNcZL38"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_path = '/content/'\n",
        "\n",
        "df_train = pd.read_csv(main_path+'train.csv')"
      ],
      "metadata": {
        "id": "1O7Z94t3bYFZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos el tamaño que tendran las imágenes."
      ],
      "metadata": {
        "id": "htXL2965XsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 225"
      ],
      "metadata": {
        "id": "nSTfTrD3fegL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "34dnaUgVWTyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d4b8c73-5af0-489f-a911-edeeba2040ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6min 5s, sys: 16.4 s, total: 6min 21s\n",
            "Wall time: 6min 20s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "X = preprocess_train_test_set(main_path, df_train['path'], image_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NN para subclases"
      ],
      "metadata": {
        "id": "IP6iDywT3B2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path + \"hierarchy_dict.json\", \"r\") as archivo:\n",
        "    hierarchy_dict = json.load(archivo)\n",
        "\n",
        "with open(path + \"food_categories_dict.json\", \"r\") as archivo:\n",
        "    food_categories_dict = json.load(archivo)\n",
        "\n",
        "with open(path + \"dish_dict.json\", \"r\") as archivo:\n",
        "    dish_dict = json.load(archivo)"
      ],
      "metadata": {
        "id": "yHT3oS7nOw18"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_dishes = transform_dishes(dish_dict, hierarchy_dict, food_categories_dict)\n",
        "\n",
        "inverse_transformed_dishes = {}\n",
        "\n",
        "for superclase, dictt in transformed_dishes.items():\n",
        "  inverse_transformed_dishes[superclase] = {value: key for key, value in dictt.items()}"
      ],
      "metadata": {
        "id": "_f2Q9crkPOrI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Superclase 1"
      ],
      "metadata": {
        "id": "TpB6SNYETzjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "superclase = 1"
      ],
      "metadata": {
        "id": "MapO_1X-wb1l"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_subclasses = len(transformed_dishes[str(superclase)])\n",
        "model_sub = create_model(image_size, n_subclasses)\n",
        "\n",
        "model_sub.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWml8qyvT1qY",
        "outputId": "4b82efab-bfc5-4f39-f9e1-1e96c3eb285c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 3s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 2048)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 1, 2048)           0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 256)               2360320   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 21)                2709      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25983637 (99.12 MB)\n",
            "Trainable params: 2395925 (9.14 MB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df_train.loc[df_train['food_category'] == int(superclase), 'dish'].map(transformed_dishes[str(superclase)])\n",
        "\n",
        "X = X[y.index]"
      ],
      "metadata": {
        "id": "MCYUPYZtSEWm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, X_val_sub, y, y_val_sub = train_test_split(X, y, test_size=0.1,\n",
        "                                              random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "jqhghvLIYqjd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = tf.one_hot(y, depth= n_subclasses)\n",
        "y_val_sub = tf.one_hot(y_val_sub, depth= n_subclasses)"
      ],
      "metadata": {
        "id": "_6-jrzbOanih"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_sub.fit(X, y,\n",
        "                        batch_size = 128,\n",
        "                        epochs = 200,\n",
        "                        callbacks=[E_S],\n",
        "                        verbose = 1,\n",
        "                        validation_data = (X_val_sub, y_val_sub)\n",
        "                        )"
      ],
      "metadata": {
        "id": "BQDiJ4ouTuss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d88ed95a-7506-4455-d0aa-50bbd60895fe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "111/111 [==============================] - 34s 164ms/step - loss: 2.2188 - macro_f1: 0.3433 - val_loss: 1.5950 - val_macro_f1: 0.5284\n",
            "Epoch 2/200\n",
            "111/111 [==============================] - 15s 136ms/step - loss: 1.6278 - macro_f1: 0.5104 - val_loss: 1.4557 - val_macro_f1: 0.5687\n",
            "Epoch 3/200\n",
            "111/111 [==============================] - 15s 135ms/step - loss: 1.4302 - macro_f1: 0.5662 - val_loss: 1.3234 - val_macro_f1: 0.6131\n",
            "Epoch 4/200\n",
            "111/111 [==============================] - 15s 135ms/step - loss: 1.3129 - macro_f1: 0.6034 - val_loss: 1.2858 - val_macro_f1: 0.6213\n",
            "Epoch 5/200\n",
            "111/111 [==============================] - 15s 134ms/step - loss: 1.2207 - macro_f1: 0.6286 - val_loss: 1.2789 - val_macro_f1: 0.6054\n",
            "Epoch 6/200\n",
            "111/111 [==============================] - 15s 135ms/step - loss: 1.1021 - macro_f1: 0.6614 - val_loss: 1.2571 - val_macro_f1: 0.6228\n",
            "Epoch 7/200\n",
            "111/111 [==============================] - 15s 136ms/step - loss: 1.0283 - macro_f1: 0.6855 - val_loss: 1.2347 - val_macro_f1: 0.6346\n",
            "Epoch 8/200\n",
            "111/111 [==============================] - 15s 135ms/step - loss: 0.9680 - macro_f1: 0.7014 - val_loss: 1.2489 - val_macro_f1: 0.6317\n",
            "Epoch 9/200\n",
            "111/111 [==============================] - 15s 134ms/step - loss: 0.8840 - macro_f1: 0.7269 - val_loss: 1.2352 - val_macro_f1: 0.6314\n",
            "Epoch 10/200\n",
            "111/111 [==============================] - 15s 135ms/step - loss: 0.8262 - macro_f1: 0.7448 - val_loss: 1.2049 - val_macro_f1: 0.6380\n",
            "Epoch 11/200\n",
            "111/111 [==============================] - 15s 135ms/step - loss: 0.7196 - macro_f1: 0.7733 - val_loss: 1.2866 - val_macro_f1: 0.6293\n",
            "Epoch 12/200\n",
            "111/111 [==============================] - 15s 134ms/step - loss: 0.6562 - macro_f1: 0.7921 - val_loss: 1.3099 - val_macro_f1: 0.6068\n",
            "Epoch 13/200\n",
            "111/111 [==============================] - 15s 134ms/step - loss: 0.6152 - macro_f1: 0.8071 - val_loss: 1.2649 - val_macro_f1: 0.6358\n",
            "Epoch 14/200\n",
            "111/111 [==============================] - 15s 134ms/step - loss: 0.5298 - macro_f1: 0.8340 - val_loss: 1.3285 - val_macro_f1: 0.6294\n",
            "Epoch 15/200\n",
            "111/111 [==============================] - 15s 134ms/step - loss: 0.4852 - macro_f1: 0.8474 - val_loss: 1.3742 - val_macro_f1: 0.6280\n",
            "Epoch 16/200\n",
            "111/111 [==============================] - 15s 134ms/step - loss: 0.4223 - macro_f1: 0.8658 - val_loss: 1.4228 - val_macro_f1: 0.6178\n",
            "Epoch 17/200\n",
            "111/111 [==============================] - 15s 134ms/step - loss: 0.3766 - macro_f1: 0.8837 - val_loss: 1.4036 - val_macro_f1: 0.6282\n",
            "Epoch 18/200\n",
            "111/111 [==============================] - 15s 134ms/step - loss: 0.3254 - macro_f1: 0.8973 - val_loss: 1.4464 - val_macro_f1: 0.6329\n",
            "Epoch 19/200\n",
            "111/111 [==============================] - 15s 134ms/step - loss: 0.2716 - macro_f1: 0.9139 - val_loss: 1.5203 - val_macro_f1: 0.6146\n",
            "Epoch 20/200\n",
            "111/111 [==============================] - 15s 136ms/step - loss: 0.2412 - macro_f1: 0.9266 - val_loss: 1.6399 - val_macro_f1: 0.6105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_sub.save(path+f'/NNs/NN_subclases_{superclase}.keras')"
      ],
      "metadata": {
        "id": "fevGG8NlvN4G"
      },
      "execution_count": 19,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}