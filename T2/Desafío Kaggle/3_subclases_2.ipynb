{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlejandroVillazonG/Tareas_INF395/blob/main/T2/3_subclases_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7m720kEWTx_"
      },
      "source": [
        "<center><img src=\"https://www.inf.utfsm.cl/images/slides/Departamento-de-Informtica_HORIZONTAL.png\" title=\"Title text\" width= 800 /></center>\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "<H1 align='center'> DESAFÍO TAREA 2</H1>\n",
        "\n",
        "<H3 align='center'> INF395 2023-2 </H3>\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "## Integrantes:\n",
        "* Joaquín Aguirre (201910031-9)\n",
        "* Alejandro Villazón (201910009-2)\n",
        "* Dominique Yessouroun (201910005-K)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvdBh0hkWTyO"
      },
      "source": [
        "Importamos las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WSGUBsGfWTyP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "import json\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "import warnings\n",
        "# Ignorar las advertencias\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos funciones auxiliares:"
      ],
      "metadata": {
        "id": "VmhHidYnW8bI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(main_path, path_image, image_size):\n",
        "    image = keras.utils.load_img(main_path + path_image)\n",
        "    image = image.resize((image_size, image_size))\n",
        "    return keras.utils.img_to_array(image, dtype='uint8')\n",
        "\n",
        "def preprocess_train_test_set(main_path, paths, image_size):\n",
        "    return np.array([preprocess_image(main_path, path_image, image_size) for path_image in paths])"
      ],
      "metadata": {
        "id": "QTZzndTLW_Ju"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_macro_f1(y_true, y_pred, num_classes):\n",
        "    \"\"\"\n",
        "    Calcula el Macro F1-Score.\n",
        "    \"\"\"\n",
        "    y_pred = tf.one_hot(tf.argmax(y_pred, axis=1), depth=num_classes)\n",
        "\n",
        "    tp = tf.cast(tf.math.count_nonzero(y_pred * y_true, axis=1), tf.float32)\n",
        "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1-y_true), axis=1), tf.float32)\n",
        "    fn = tf.cast(tf.math.count_nonzero((1-y_pred) * y_true, axis=1), tf.float32)\n",
        "\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "\n",
        "    f1 = 2*precision*recall / (precision + recall)\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "\n",
        "    return tf.reduce_mean(f1)\n",
        "\n",
        "def transform_dishes(original_dishes, mapping_dishes, category_mapping):\n",
        "    transformed_dishes = {}\n",
        "    for original_key, dish in original_dishes.items():\n",
        "        for category_key, category_value in category_mapping.items():\n",
        "            if dish in mapping_dishes[category_value].values():\n",
        "                # Encontrar la clave interna dentro del diccionario de categoría\n",
        "                internal_key = [int(k) for k, v in mapping_dishes[category_value].items() if v == dish][0]\n",
        "                # Convertir la clave original a int para guardarla en el resultado\n",
        "                original_key_int = int(original_key)\n",
        "                # Asegurar que la categoría exista en el diccionario resultante\n",
        "                if category_key not in transformed_dishes:\n",
        "                    transformed_dishes[category_key] = {}\n",
        "                # Agregar el mapeo al diccionario resultante\n",
        "                transformed_dishes[category_key][original_key_int] = internal_key\n",
        "    return transformed_dishes\n",
        "\n",
        "def create_model(image_size, num_classes):\n",
        "  cnn_model = ResNet50(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "  for layer in cnn_model.layers:\n",
        "      layer.trainable = False\n",
        "  model = keras.Sequential([\n",
        "      cnn_model,\n",
        "      # layers.Conv2D(512, 2, activation='relu'),\n",
        "      # layers.MaxPooling2D(pool_size=2),\n",
        "\n",
        "      layers.GlobalAveragePooling2D(),\n",
        "      layers.Reshape((1, -1)),\n",
        "      layers.LSTM(256),\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      layers.Dropout(0.5),\n",
        "      layers.Dense(num_classes, activation='softmax')\n",
        "  ])\n",
        "  def macro_f1(y_true, y_pred):\n",
        "    return create_macro_f1(y_true, y_pred, num_classes)\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.AdamW(),\n",
        "                loss=['categorical_crossentropy'],\n",
        "                metrics=[macro_f1])\n",
        "  return model"
      ],
      "metadata": {
        "id": "YNdBJwNSXCTP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "E_S = keras.callbacks.EarlyStopping(monitor='val_macro_f1', mode='max',\n",
        "                                    patience=10, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "5LAyfQYRhxNX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos conectamos al drive:"
      ],
      "metadata": {
        "id": "9oYVGuIYXjFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M2A0Nv4WlFv",
        "outputId": "fe1b3462-8ef3-4180-ff0d-da622b89e81b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dHG0rtlsWTyW"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/INF395/T2/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesar imágenes"
      ],
      "metadata": {
        "id": "bbKmwOCq_JpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '{path}inf-395-tarea-2.zip'  > /dev/null"
      ],
      "metadata": {
        "id": "zt_ZZPNcZL38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "683a40e4-ba35-4852-8bee-c8649261b7ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace dish_dict.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_path = '/content/'\n",
        "\n",
        "df_train = pd.read_csv(main_path+'train.csv')"
      ],
      "metadata": {
        "id": "1O7Z94t3bYFZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos el tamaño que tendran las imágenes."
      ],
      "metadata": {
        "id": "htXL2965XsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 225"
      ],
      "metadata": {
        "id": "nSTfTrD3fegL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "34dnaUgVWTyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1589c194-2483-4d10-f31c-5c10826b2172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5min 29s, sys: 15.5 s, total: 5min 44s\n",
            "Wall time: 7min 2s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "X = preprocess_train_test_set(main_path, df_train['path'], image_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NN para subclases"
      ],
      "metadata": {
        "id": "IP6iDywT3B2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path + \"hierarchy_dict.json\", \"r\") as archivo:\n",
        "    hierarchy_dict = json.load(archivo)\n",
        "\n",
        "with open(path + \"food_categories_dict.json\", \"r\") as archivo:\n",
        "    food_categories_dict = json.load(archivo)\n",
        "\n",
        "with open(path + \"dish_dict.json\", \"r\") as archivo:\n",
        "    dish_dict = json.load(archivo)"
      ],
      "metadata": {
        "id": "yHT3oS7nOw18"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_dishes = transform_dishes(dish_dict, hierarchy_dict, food_categories_dict)\n",
        "\n",
        "inverse_transformed_dishes = {}\n",
        "\n",
        "for superclase, dictt in transformed_dishes.items():\n",
        "  inverse_transformed_dishes[superclase] = {value: key for key, value in dictt.items()}"
      ],
      "metadata": {
        "id": "_f2Q9crkPOrI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Superclase 2"
      ],
      "metadata": {
        "id": "TpB6SNYETzjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "superclase = 2"
      ],
      "metadata": {
        "id": "PqxfTG3IweBr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_subclasses = len(transformed_dishes[str(superclase)])\n",
        "model_sub = create_model(image_size, n_subclasses)\n",
        "\n",
        "model_sub.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWml8qyvT1qY",
        "outputId": "38701b4f-103c-492f-eb3f-3f3edf6a1c56"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 2048)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 1, 2048)           0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 256)               2360320   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 75)                9675      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25990603 (99.15 MB)\n",
            "Trainable params: 2402891 (9.17 MB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df_train.loc[df_train['food_category'] == int(superclase), 'dish'].map(transformed_dishes[str(superclase)])\n",
        "\n",
        "X = X[y.index]"
      ],
      "metadata": {
        "id": "MCYUPYZtSEWm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, X_val_sub, y, y_val_sub = train_test_split(X, y, test_size=0.1,\n",
        "                                              random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "jqhghvLIYqjd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = tf.one_hot(y, depth= n_subclasses)\n",
        "y_val_sub = tf.one_hot(y_val_sub, depth= n_subclasses)"
      ],
      "metadata": {
        "id": "_6-jrzbOanih"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_sub.fit(X, y,\n",
        "                        batch_size = 64,\n",
        "                        epochs = 200,\n",
        "                        callbacks=[E_S],\n",
        "                        verbose = 1,\n",
        "                        validation_data = (X_val_sub, y_val_sub)\n",
        "                        )"
      ],
      "metadata": {
        "id": "BQDiJ4ouTuss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c661804d-022f-407d-8689-cedefecfb7cc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "792/792 [==============================] - 76s 77ms/step - loss: 3.2143 - macro_f1: 0.2115 - val_loss: 2.5677 - val_macro_f1: 0.3538\n",
            "Epoch 2/200\n",
            "792/792 [==============================] - 58s 73ms/step - loss: 2.5435 - macro_f1: 0.3507 - val_loss: 2.2639 - val_macro_f1: 0.4266\n",
            "Epoch 3/200\n",
            "792/792 [==============================] - 58s 74ms/step - loss: 2.3141 - macro_f1: 0.4066 - val_loss: 2.0972 - val_macro_f1: 0.4689\n",
            "Epoch 4/200\n",
            "792/792 [==============================] - 58s 73ms/step - loss: 2.1714 - macro_f1: 0.4386 - val_loss: 2.0211 - val_macro_f1: 0.4643\n",
            "Epoch 5/200\n",
            "792/792 [==============================] - 59s 74ms/step - loss: 2.0797 - macro_f1: 0.4594 - val_loss: 1.9709 - val_macro_f1: 0.4914\n",
            "Epoch 6/200\n",
            "792/792 [==============================] - 59s 74ms/step - loss: 1.9841 - macro_f1: 0.4799 - val_loss: 1.9857 - val_macro_f1: 0.4845\n",
            "Epoch 7/200\n",
            "792/792 [==============================] - 58s 74ms/step - loss: 1.9318 - macro_f1: 0.4906 - val_loss: 1.9582 - val_macro_f1: 0.4894\n",
            "Epoch 8/200\n",
            "792/792 [==============================] - 59s 74ms/step - loss: 1.8481 - macro_f1: 0.5115 - val_loss: 1.9010 - val_macro_f1: 0.4993\n",
            "Epoch 9/200\n",
            "792/792 [==============================] - 58s 74ms/step - loss: 1.7915 - macro_f1: 0.5222 - val_loss: 2.0023 - val_macro_f1: 0.4841\n",
            "Epoch 10/200\n",
            "792/792 [==============================] - 58s 74ms/step - loss: 1.7739 - macro_f1: 0.5289 - val_loss: 1.8900 - val_macro_f1: 0.5082\n",
            "Epoch 11/200\n",
            "792/792 [==============================] - 58s 74ms/step - loss: 1.6920 - macro_f1: 0.5470 - val_loss: 1.9297 - val_macro_f1: 0.5032\n",
            "Epoch 12/200\n",
            "792/792 [==============================] - 59s 74ms/step - loss: 1.6397 - macro_f1: 0.5570 - val_loss: 1.8848 - val_macro_f1: 0.5116\n",
            "Epoch 13/200\n",
            "792/792 [==============================] - 59s 74ms/step - loss: 1.5881 - macro_f1: 0.5709 - val_loss: 1.8802 - val_macro_f1: 0.5117\n",
            "Epoch 14/200\n",
            "792/792 [==============================] - 59s 74ms/step - loss: 1.5576 - macro_f1: 0.5766 - val_loss: 1.9083 - val_macro_f1: 0.5125\n",
            "Epoch 15/200\n",
            "792/792 [==============================] - 58s 74ms/step - loss: 1.5017 - macro_f1: 0.5863 - val_loss: 1.8896 - val_macro_f1: 0.5120\n",
            "Epoch 16/200\n",
            "792/792 [==============================] - 58s 74ms/step - loss: 1.4716 - macro_f1: 0.5941 - val_loss: 1.9249 - val_macro_f1: 0.5102\n",
            "Epoch 17/200\n",
            "792/792 [==============================] - 59s 74ms/step - loss: 1.4503 - macro_f1: 0.5965 - val_loss: 1.9234 - val_macro_f1: 0.5135\n",
            "Epoch 18/200\n",
            "792/792 [==============================] - 59s 74ms/step - loss: 1.4295 - macro_f1: 0.6049 - val_loss: 1.9204 - val_macro_f1: 0.5133\n",
            "Epoch 19/200\n",
            "792/792 [==============================] - 59s 74ms/step - loss: 1.3829 - macro_f1: 0.6168 - val_loss: 1.9228 - val_macro_f1: 0.5103\n",
            "Epoch 20/200\n",
            "792/792 [==============================] - 59s 74ms/step - loss: 1.3342 - macro_f1: 0.6238 - val_loss: 1.9937 - val_macro_f1: 0.5015\n",
            "Epoch 21/200\n",
            "792/792 [==============================] - 58s 74ms/step - loss: 1.3080 - macro_f1: 0.6316 - val_loss: 1.9636 - val_macro_f1: 0.5126\n",
            "Epoch 22/200\n",
            "792/792 [==============================] - 58s 74ms/step - loss: 1.2682 - macro_f1: 0.6397 - val_loss: 2.0236 - val_macro_f1: 0.5041\n",
            "Epoch 23/200\n",
            "792/792 [==============================] - 59s 74ms/step - loss: 1.2522 - macro_f1: 0.6440 - val_loss: 2.1251 - val_macro_f1: 0.4913\n",
            "Epoch 24/200\n",
            "792/792 [==============================] - 59s 74ms/step - loss: 1.2981 - macro_f1: 0.6325 - val_loss: 2.0446 - val_macro_f1: 0.5088\n",
            "Epoch 25/200\n",
            "792/792 [==============================] - 59s 74ms/step - loss: 1.2180 - macro_f1: 0.6520 - val_loss: 2.0463 - val_macro_f1: 0.5061\n",
            "Epoch 26/200\n",
            "792/792 [==============================] - 59s 74ms/step - loss: 1.1861 - macro_f1: 0.6574 - val_loss: 2.0598 - val_macro_f1: 0.5001\n",
            "Epoch 27/200\n",
            "792/792 [==============================] - 59s 74ms/step - loss: 1.1827 - macro_f1: 0.6595 - val_loss: 2.0692 - val_macro_f1: 0.5009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_sub.save(path+f'NNs/NN_subclases_{superclase}.keras')"
      ],
      "metadata": {
        "id": "fevGG8NlvN4G"
      },
      "execution_count": 20,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}